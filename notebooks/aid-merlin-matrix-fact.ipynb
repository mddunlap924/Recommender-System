{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:19:23.231728Z","iopub.status.busy":"2022-12-08T09:19:23.231262Z","iopub.status.idle":"2022-12-08T09:19:48.359168Z","shell.execute_reply":"2022-12-08T09:19:48.358053Z","shell.execute_reply.started":"2022-12-08T09:19:23.231621Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Unique Aids: 1,825,499\n","Test Unique Aids: 874,852\n","Unique Aids: 1,844,284\n"]}],"source":["import cudf\n","import pandas as pd\n","from utils.data.load_data import cache_data_to_cpu\n","import numpy as np\n","from pathlib import Path\n","\n","APPROACH = 'validation'\n","\n","if APPROACH == 'validation':\n","    base_path = '../data/otto-validation'\n","elif APPROACH == 'test':\n","    base_path = '../data/otto-chunk-data-inparquet-format'\n","\n","# Cache data to RAM\n","\n","train_cache, _ = cache_data_to_cpu(data_path=base_path, data_seg='train')\n","test_cache, _ = cache_data_to_cpu(data_path=base_path, data_seg='test')\n","\n","# Go from dictionary to single dataframe\n","train = pd.concat([df for _, df in train_cache.items()])\n","test = pd.concat([df for _, df in test_cache.items()]) \n","\n","unique_aids = train.aid.unique().tolist() + test.aid.unique().tolist()\n","unique_aids = np.sort(np.unique(unique_aids))\n","\n","print(f'Train Unique Aids: {train.aid.nunique():,}')\n","print(f'Test Unique Aids: {test.aid.nunique():,}')\n","print(f'Unique Aids: {len(unique_aids):,}')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Max Value Aids: 1,855,602\n","Min Value Aids: 0\n"]}],"source":["print(f'Max Value Aids: {max(unique_aids):,}')\n","print(f'Min Value Aids: {min(unique_aids):,}')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train = cudf.from_pandas(train)\n","test = cudf.from_pandas(test)"]},{"cell_type":"markdown","metadata":{},"source":["We need to create `aid-aid` pairs to train our matrix factorization model!\n","\n","Let's us grab the pairs both from the train and test set."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:19:48.362002Z","iopub.status.busy":"2022-12-08T09:19:48.361391Z","iopub.status.idle":"2022-12-08T09:19:50.338699Z","shell.execute_reply":"2022-12-08T09:19:50.337355Z","shell.execute_reply.started":"2022-12-08T09:19:48.361961Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 281 ms, sys: 273 ms, total: 554 ms\n","Wall time: 553 ms\n"]}],"source":["%%time\n","\n","train_pairs = cudf.concat([train, test])[['session', 'aid']]\n","del train, test\n","\n","train_pairs['aid_next'] = train_pairs.groupby('session').aid.shift(-1)\n","train_pairs = train_pairs[['aid', 'aid_next']].dropna().reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["The running time is 15x better than when using polar with CPU!"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:19:50.346035Z","iopub.status.busy":"2022-12-08T09:19:50.343253Z","iopub.status.idle":"2022-12-08T09:19:50.362772Z","shell.execute_reply":"2022-12-08T09:19:50.359408Z","shell.execute_reply.started":"2022-12-08T09:19:50.345988Z"},"trusted":true},"outputs":[{"data":{"text/plain":["158.738978"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_pairs.shape[0] / 1_000_000"]},{"cell_type":"markdown","metadata":{},"source":["That is 209 million pairs created in 40 seconds without running out of RAM! ðŸ™‚ Not too bad"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:19:50.369149Z","iopub.status.busy":"2022-12-08T09:19:50.367962Z","iopub.status.idle":"2022-12-08T09:19:50.427827Z","shell.execute_reply":"2022-12-08T09:19:50.426909Z","shell.execute_reply.started":"2022-12-08T09:19:50.369111Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aid</th>\n","      <th>aid_next</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>625184</td>\n","      <td>559816</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>559816</td>\n","      <td>559816</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>559816</td>\n","      <td>1021135</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1021135</td>\n","      <td>559816</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>559816</td>\n","      <td>1630441</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       aid  aid_next\n","0   625184    559816\n","1   559816    559816\n","2   559816   1021135\n","3  1021135    559816\n","4   559816   1630441"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_pairs.head()"]},{"cell_type":"markdown","metadata":{},"source":["Let's see what is the cardinality of our aids -- we will need this to create the embedding layer."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:19:50.431114Z","iopub.status.busy":"2022-12-08T09:19:50.430741Z","iopub.status.idle":"2022-12-08T09:19:50.46629Z","shell.execute_reply":"2022-12-08T09:19:50.465207Z","shell.execute_reply.started":"2022-12-08T09:19:50.431072Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1855602"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["cardinality_aids = max(train_pairs['aid'].max(), train_pairs['aid_next'].max())\n","cardinality_aids"]},{"cell_type":"markdown","metadata":{},"source":["We will have up to `1855602` -- that is a lot! But our matrix factorization model will be able to handle this.\n"]},{"cell_type":"markdown","metadata":{},"source":["Oh dear, that took forever! Mind you, were are not doing anything here, apart from iterating over the dataset for a single epoch (and that is without validation!).\n","\n","The reason this is taking so long is that indexing into the the arrays and collating results into batches is very computationally expensive.\n","\n","There are ways to work around this but they require writing a lot of code (you could use the iterable-style dataset). And still our solution wouldn't be particularly well optimized.\n","\n","Let us do something else instead!\n","\n","We will use a brand new [Merlin Dataloader](https://github.com/NVIDIA-Merlin/dataloader). It is a library that my team launched just a couple of days ago ðŸ™‚\n","\n","Now this library shines when you have a GPU, which is what you generally want when training DL models. But, alas, Kaggle gives you only 13 GB of RAM on a kernel with a GPU, and that wouldn't allow us to process our dataset!\n","\n","Let's see how far we can get with CPU only."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:21:20.029195Z","iopub.status.busy":"2022-12-08T09:21:20.028721Z","iopub.status.idle":"2022-12-08T09:21:22.137243Z","shell.execute_reply":"2022-12-08T09:21:22.136155Z","shell.execute_reply.started":"2022-12-08T09:21:20.029161Z"},"trusted":true},"outputs":[],"source":["from merlin.loader.torch import Loader "]},{"cell_type":"markdown","metadata":{},"source":["We can read data directly from the disk -- even better!\n","\n","Let's write our datasets to disk."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:21:22.139175Z","iopub.status.busy":"2022-12-08T09:21:22.138802Z","iopub.status.idle":"2022-12-08T09:21:34.226301Z","shell.execute_reply":"2022-12-08T09:21:34.225212Z","shell.execute_reply.started":"2022-12-08T09:21:22.139138Z"},"trusted":true},"outputs":[],"source":["train_pairs[:-10_000_000].to_pandas().to_parquet('train_pairs.parquet')\n","train_pairs[-10_000_000:].to_pandas().to_parquet('valid_pairs.parquet')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:21:34.228166Z","iopub.status.busy":"2022-12-08T09:21:34.227763Z","iopub.status.idle":"2022-12-08T09:21:35.098436Z","shell.execute_reply":"2022-12-08T09:21:35.097358Z","shell.execute_reply.started":"2022-12-08T09:21:34.228127Z"},"trusted":true},"outputs":[],"source":["from merlin.loader.torch import Loader \n","from merlin.io import Dataset\n","\n","train_ds = Dataset('train_pairs.parquet')\n","train_dl_merlin = Loader(train_ds, 65536, True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:21:35.100234Z","iopub.status.busy":"2022-12-08T09:21:35.099809Z","iopub.status.idle":"2022-12-08T09:21:38.341848Z","shell.execute_reply":"2022-12-08T09:21:38.340816Z","shell.execute_reply.started":"2022-12-08T09:21:35.100193Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 905 ms, sys: 414 ms, total: 1.32 s\n","Wall time: 1.63 s\n"]}],"source":["%%time\n","\n","for batch in train_dl_merlin:\n","    aid1, aid2 = batch[0], batch[1]"]},{"cell_type":"markdown","metadata":{},"source":["That is much better ðŸ™‚. Let's train our matrix factorization model!"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:23:51.967661Z","iopub.status.busy":"2022-12-08T09:23:51.967216Z","iopub.status.idle":"2022-12-08T09:23:52.129883Z","shell.execute_reply":"2022-12-08T09:23:52.128862Z","shell.execute_reply.started":"2022-12-08T09:23:51.967624Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","class MatrixFactorization(nn.Module):\n","    def __init__(self, n_aids, n_factors):\n","        super().__init__()\n","        self.aid_factors = nn.Embedding(n_aids, n_factors, sparse=True)\n","        \n","    def forward(self, aid1, aid2):\n","        aid1 = self.aid_factors(aid1)\n","        aid2 = self.aid_factors(aid2)\n","        \n","        return (aid1 * aid2).sum(dim=1)\n","    \n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","valid_ds = Dataset('valid_pairs.parquet')\n","valid_dl_merlin = Loader(valid_ds, 65536, True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:25:02.537511Z","iopub.status.busy":"2022-12-08T09:25:02.53673Z","iopub.status.idle":"2022-12-08T09:25:03.019582Z","shell.execute_reply":"2022-12-08T09:25:03.018534Z","shell.execute_reply.started":"2022-12-08T09:25:02.537469Z"},"trusted":true},"outputs":[],"source":["from torch.optim import SparseAdam\n","\n","num_epochs=10\n","lr=0.1\n","\n","model = MatrixFactorization(cardinality_aids+1, 32)\n","optimizer = SparseAdam(model.parameters(), lr=lr)\n","criterion = nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:25:05.688207Z","iopub.status.busy":"2022-12-08T09:25:05.687807Z","iopub.status.idle":"2022-12-08T09:25:30.337578Z","shell.execute_reply":"2022-12-08T09:25:30.336476Z","shell.execute_reply.started":"2022-12-08T09:25:05.688176Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["01: * TrainLoss 0.620  * Accuracy 0.705\n","02: * TrainLoss 0.613  * Accuracy 0.714\n","03: * TrainLoss 0.611  * Accuracy 0.718\n","04: * TrainLoss 0.606  * Accuracy 0.719\n","05: * TrainLoss 0.606  * Accuracy 0.720\n","06: * TrainLoss 0.607  * Accuracy 0.721\n","07: * TrainLoss 0.603  * Accuracy 0.721\n","08: * TrainLoss 0.604  * Accuracy 0.721\n","09: * TrainLoss 0.605  * Accuracy 0.722\n","10: * TrainLoss 0.605  * Accuracy 0.722\n","CPU times: user 11min 17s, sys: 1.7 s, total: 11min 18s\n","Wall time: 1min 29s\n"]}],"source":["%%time\n","model.to('cuda')\n","for epoch in range(num_epochs):\n","    for batch, _ in train_dl_merlin:\n","        model.train()\n","        losses = AverageMeter('Loss', ':.4e')\n","            \n","        aid1, aid2 = batch['aid'], batch['aid_next']\n","        aid1 = aid1.to('cuda')\n","        aid2 = aid2.to('cuda')\n","        output_pos = model(aid1, aid2)\n","        output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])])\n","        \n","        output = torch.cat([output_pos, output_neg])\n","        targets = torch.cat([torch.ones_like(output_pos), torch.zeros_like(output_pos)])\n","        loss = criterion(output, targets)\n","        losses.update(loss.item())\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    model.eval()\n","    \n","    with torch.no_grad():\n","        accuracy = AverageMeter('accuracy')\n","        for batch, _ in valid_dl_merlin:\n","            aid1, aid2 = batch['aid'], batch['aid_next']\n","            output_pos = model(aid1, aid2)\n","            output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])])\n","            accuracy_batch = torch.cat([output_pos.sigmoid() > 0.5, output_neg.sigmoid() < 0.5]).float().mean()\n","            accuracy.update(accuracy_batch, aid1.shape[0])\n","            \n","    print(f'{epoch+1:02d}: * TrainLoss {losses.avg:.3f}  * Accuracy {accuracy.avg:.3f}')"]},{"cell_type":"markdown","metadata":{},"source":["This code ran about 60x faster than the cpu code form Radek's notebook. And we have not tuned the batch size! Using GPU larger batch size is possible which would reduce the running time further."]},{"cell_type":"markdown","metadata":{},"source":["Let's grab the embeddings!"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:27:06.092101Z","iopub.status.busy":"2022-12-08T09:27:06.091705Z","iopub.status.idle":"2022-12-08T09:27:06.285784Z","shell.execute_reply":"2022-12-08T09:27:06.284836Z","shell.execute_reply.started":"2022-12-08T09:27:06.092067Z"},"trusted":true},"outputs":[],"source":["embeddings = model.aid_factors.weight.detach().cpu().numpy()"]},{"cell_type":"markdown","metadata":{},"source":["And construct create the index for approximate nearest neighbor search. We will use cuml for that."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:28:57.121322Z","iopub.status.busy":"2022-12-08T09:28:57.12019Z","iopub.status.idle":"2022-12-08T09:28:57.511365Z","shell.execute_reply":"2022-12-08T09:28:57.510356Z","shell.execute_reply.started":"2022-12-08T09:28:57.121281Z"},"trusted":true},"outputs":[],"source":["from cuml.neighbors import NearestNeighbors"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:40:01.460041Z","iopub.status.busy":"2022-12-08T09:40:01.459632Z","iopub.status.idle":"2022-12-08T09:40:01.467068Z","shell.execute_reply":"2022-12-08T09:40:01.465616Z","shell.execute_reply.started":"2022-12-08T09:40:01.460008Z"}},"source":["We will compute 21 nearest neighbors as in Radek's notebook. "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:42:55.308583Z","iopub.status.busy":"2022-12-08T09:42:55.30773Z","iopub.status.idle":"2022-12-08T09:42:55.367333Z","shell.execute_reply":"2022-12-08T09:42:55.366297Z","shell.execute_reply.started":"2022-12-08T09:42:55.308542Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 16.5 ms, sys: 92 ms, total: 108 ms\n","Wall time: 112 ms\n"]},{"data":{"text/plain":["NearestNeighbors()"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","\n","knn = NearestNeighbors(n_neighbors=21, metric='euclidean')\n","knn.fit(embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["Now for any `aid`, we can find its nearest neighbor! cuml let you do this in parallel for all input at once."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:42:56.950161Z","iopub.status.busy":"2022-12-08T09:42:56.949102Z","iopub.status.idle":"2022-12-08T09:44:09.780045Z","shell.execute_reply":"2022-12-08T09:44:09.778951Z","shell.execute_reply.started":"2022-12-08T09:42:56.950121Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 48.3 s, sys: 156 ms, total: 48.5 s\n","Wall time: 48.4 s\n"]}],"source":["%%time\n","\n","_, aid_nns = knn.kneighbors(embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["Let's check we get 21 neighbors for each aid:"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:44:09.783728Z","iopub.status.busy":"2022-12-08T09:44:09.783431Z","iopub.status.idle":"2022-12-08T09:44:09.794025Z","shell.execute_reply":"2022-12-08T09:44:09.793033Z","shell.execute_reply.started":"2022-12-08T09:44:09.783693Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(1855603, 21)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["aid_nns.shape"]},{"cell_type":"markdown","metadata":{},"source":["We can get rid of the first neigbor directly."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["array([      0,  435927, 1532058, 1331180, 1196094,   54213, 1303929,\n","       1362288, 1475885,  810679, 1346918,  277765, 1411300,  166411,\n","        748568,  719910, 1140826, 1503167, 1656874,   89497,  926200])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["aid_nns[0]"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-12-08T09:44:09.804614Z","iopub.status.busy":"2022-12-08T09:44:09.804175Z","iopub.status.idle":"2022-12-08T09:44:09.809459Z","shell.execute_reply":"2022-12-08T09:44:09.808265Z","shell.execute_reply.started":"2022-12-08T09:44:09.804577Z"},"trusted":true},"outputs":[],"source":["aid_nns = aid_nns[:, 1:]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(1855603, 20)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["aid_nns.shape"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nn_0</th>\n","      <th>nn_1</th>\n","      <th>nn_2</th>\n","      <th>nn_3</th>\n","      <th>nn_4</th>\n","      <th>nn_5</th>\n","      <th>nn_6</th>\n","      <th>nn_7</th>\n","      <th>nn_8</th>\n","      <th>nn_9</th>\n","      <th>nn_10</th>\n","      <th>nn_11</th>\n","      <th>nn_12</th>\n","      <th>nn_13</th>\n","      <th>nn_14</th>\n","      <th>nn_15</th>\n","      <th>nn_16</th>\n","      <th>nn_17</th>\n","      <th>nn_18</th>\n","      <th>nn_19</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>435927</td>\n","      <td>1532058</td>\n","      <td>1331180</td>\n","      <td>1196094</td>\n","      <td>54213</td>\n","      <td>1303929</td>\n","      <td>1362288</td>\n","      <td>1475885</td>\n","      <td>810679</td>\n","      <td>1346918</td>\n","      <td>277765</td>\n","      <td>1411300</td>\n","      <td>166411</td>\n","      <td>748568</td>\n","      <td>719910</td>\n","      <td>1140826</td>\n","      <td>1503167</td>\n","      <td>1656874</td>\n","      <td>89497</td>\n","      <td>926200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1183939</td>\n","      <td>315834</td>\n","      <td>1408104</td>\n","      <td>417868</td>\n","      <td>759057</td>\n","      <td>1328127</td>\n","      <td>1156408</td>\n","      <td>1481588</td>\n","      <td>1017121</td>\n","      <td>1139392</td>\n","      <td>1223000</td>\n","      <td>310100</td>\n","      <td>1509196</td>\n","      <td>1663913</td>\n","      <td>617652</td>\n","      <td>1088867</td>\n","      <td>1072540</td>\n","      <td>105737</td>\n","      <td>641836</td>\n","      <td>588686</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1287855</td>\n","      <td>1839810</td>\n","      <td>1209089</td>\n","      <td>1772209</td>\n","      <td>1080360</td>\n","      <td>155993</td>\n","      <td>1392978</td>\n","      <td>925419</td>\n","      <td>27086</td>\n","      <td>1814441</td>\n","      <td>1543007</td>\n","      <td>1209041</td>\n","      <td>1554563</td>\n","      <td>412636</td>\n","      <td>1067902</td>\n","      <td>1320053</td>\n","      <td>429342</td>\n","      <td>1196561</td>\n","      <td>1770094</td>\n","      <td>1081344</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>828344</td>\n","      <td>1741562</td>\n","      <td>1818695</td>\n","      <td>347257</td>\n","      <td>16778</td>\n","      <td>1229277</td>\n","      <td>1252701</td>\n","      <td>1160686</td>\n","      <td>750061</td>\n","      <td>316488</td>\n","      <td>873918</td>\n","      <td>597886</td>\n","      <td>1602679</td>\n","      <td>64692</td>\n","      <td>1152909</td>\n","      <td>1762469</td>\n","      <td>258325</td>\n","      <td>93004</td>\n","      <td>1403776</td>\n","      <td>776187</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1730772</td>\n","      <td>1115393</td>\n","      <td>389702</td>\n","      <td>103787</td>\n","      <td>1018902</td>\n","      <td>1065060</td>\n","      <td>211393</td>\n","      <td>573353</td>\n","      <td>1358045</td>\n","      <td>1429258</td>\n","      <td>317290</td>\n","      <td>409609</td>\n","      <td>530363</td>\n","      <td>523774</td>\n","      <td>1020053</td>\n","      <td>129508</td>\n","      <td>443671</td>\n","      <td>852073</td>\n","      <td>1059300</td>\n","      <td>254580</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      nn_0     nn_1     nn_2     nn_3     nn_4     nn_5     nn_6     nn_7  \\\n","0   435927  1532058  1331180  1196094    54213  1303929  1362288  1475885   \n","1  1183939   315834  1408104   417868   759057  1328127  1156408  1481588   \n","2  1287855  1839810  1209089  1772209  1080360   155993  1392978   925419   \n","3   828344  1741562  1818695   347257    16778  1229277  1252701  1160686   \n","4  1730772  1115393   389702   103787  1018902  1065060   211393   573353   \n","\n","      nn_8     nn_9    nn_10    nn_11    nn_12    nn_13    nn_14    nn_15  \\\n","0   810679  1346918   277765  1411300   166411   748568   719910  1140826   \n","1  1017121  1139392  1223000   310100  1509196  1663913   617652  1088867   \n","2    27086  1814441  1543007  1209041  1554563   412636  1067902  1320053   \n","3   750061   316488   873918   597886  1602679    64692  1152909  1762469   \n","4  1358045  1429258   317290   409609   530363   523774  1020053   129508   \n","\n","     nn_16    nn_17    nn_18    nn_19  \n","0  1503167  1656874    89497   926200  \n","1  1072540   105737   641836   588686  \n","2   429342  1196561  1770094  1081344  \n","3   258325    93004  1403776   776187  \n","4   443671   852073  1059300   254580  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Save matrix to disk\n","cols = [f'nn_{i}' for i in range(aid_nns.shape[1])]\n","data = pd.DataFrame(aid_nns, columns=cols)\n","save_base = Path('../output/matrix-fac')\n","file_path = save_base / APPROACH / 'nn20.parquet'\n","data.to_parquet(file_path)\n","data.head()"]}],"metadata":{"kernelspec":{"display_name":"kaggle-sysrec","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:45:29) \n[GCC 10.4.0]"},"vscode":{"interpreter":{"hash":"1c4289c30b9ee1fe1eef6359bd2a5afe029512428bdda19c76465a4efe5722eb"}}},"nbformat":4,"nbformat_minor":4}
